# Telemetry Testing Scripts

These scripts help you generate test data to verify your Grafana dashboards are working correctly.

## Prerequisites

1. Make sure your application is running: `bun run dev`
2. Ensure OpenTelemetry stack is up (Grafana, Prometheus, OTEL Collector)
3. Open Grafana dashboard at http://localhost:3001

## Scripts Overview

### 1. Continuous Traffic Generator

Generates realistic HTTP traffic to your application by making actual requests.

```bash
bun run telemetry:traffic
```

**Environment Variables:**
- `BASE_URL` - Target URL (default: http://localhost:3000)
- `DURATION_MINUTES` - How long to run (default: 5)
- `REQUESTS_PER_MINUTE` - Request rate (default: 10)

**Example:**
```bash
DURATION_MINUTES=10 REQUESTS_PER_MINUTE=20 bun run telemetry:traffic
```

**What it generates:**
- HTTP Client Request Rate metrics
- HTTP Requests by Endpoint metrics
- Various response times and status codes

### 2. Login Metrics Generator

Generates login activity metrics directly.

```bash
bun run telemetry:login [num_attempts]
```

**Options:**
- First argument: Number of login attempts (default: 30)
- `--burst`: Also generate a burst of failed login attempts

**Examples:**
```bash
# Generate 50 login attempts
bun run telemetry:login 50

# Generate with failed login burst (simulates attack)
bun run telemetry:login 50 --burst
```

**What it generates:**
- Login Activity metrics (attempts, success, failures)
- New location login metrics
- Suspicious login metrics

### 3. Full Telemetry Generator

Generates a variety of telemetry data including HTTP, API, login, and database metrics.

```bash
bun run telemetry:test
```

**What it generates:**
- HTTP client request metrics
- API error metrics
- Login activity metrics
- Database query metrics

## Dashboard Panels

Your [application-overview.json](/.devcontainer/grafana/dashboards/application-overview.json) dashboard expects these metrics:

### Panel 1: HTTP Client Request Rate
- Metric: `rate(devacademy_http_client_request_duration_seconds_count[5m])`
- Generated by: Continuous Traffic Generator
- Shows: Requests per second to different endpoints

### Panel 2: Average HTTP Client Response Time
- Metric: `rate(devacademy_http_client_request_duration_seconds_sum[5m]) / rate(devacademy_http_client_request_duration_seconds_count[5m])`
- Generated by: Continuous Traffic Generator
- Shows: Average latency in milliseconds

### Panel 3: API Error Rate
- Metric: `rate(devacademy_api_errors_total[5m])`
- Generated by: Full Telemetry Generator
- Shows: API errors per second by type

### Panel 4: Login Activity
- Metrics:
  - `rate(devacademy_user_login_attempts_total[5m])`
  - `rate(devacademy_user_login_success_total[5m])`
  - `rate(devacademy_user_login_failures_total[5m])`
- Generated by: Login Metrics Generator
- Shows: Login attempts, successes, and failures

### Panel 5: Database Query Rate
- Metric: `rate(devacademy_db_client_operation_duration_seconds_count[5m])`
- Generated by: Full Telemetry Generator
- Shows: Database operations per second

### Panel 6: HTTP Requests by Endpoint
- Metric: `sum by (server_address) (rate(devacademy_http_client_request_duration_seconds_count[5m]))`
- Generated by: Continuous Traffic Generator
- Shows: Distribution of requests across endpoints

## Viewing the Data

1. **Wait for metrics export**:
   - Metrics are exported every 15 seconds
   - The test scripts wait 20 seconds to ensure metrics are exported before exiting
   - After running a script, wait for it to complete fully before checking Grafana

2. **Check Prometheus**: Verify metrics are being collected
   ```bash
   # List all metrics with "devacademy" prefix
   curl -s http://localhost:9090/api/v1/label/__name__/values | jq -r '.data[]' | grep devacademy

   # Query specific metrics to see if they have data
   curl -s 'http://localhost:9090/api/v1/query?query=devacademy_user_login_attempts_total'
   ```

3. **View in Grafana**:
   - Navigate to http://localhost:3001
   - Go to Dashboards → DevAcademy → Application Overview
   - Set time range to "Last 15 minutes"
   - Click "Refresh" button
   - If no data appears, wait 15 more seconds and click refresh again

## Troubleshooting

### No data showing in dashboard

1. **View raw metrics directly** (very helpful for debugging):
   - Open http://localhost:9090/metrics in your browser
   - This shows all metrics that Prometheus is collecting
   - Search for `devacademy_` to find your application metrics
   - Verify metric names match what your dashboard queries expect

2. Check if metrics are being exported:
   ```bash
   # Check Prometheus targets
   curl http://localhost:9090/api/v1/targets
   ```

3. Check OTEL collector logs:
   ```bash
   docker logs otel-collector
   ```

4. Verify your app is instrumented:
   ```bash
   # You should see this in your app logs
   # ✅ OpenTelemetry instrumentation initialized
   ```

### Metrics have wrong names

The dashboard expects specific metric names with the `devacademy_` prefix. Check [instrumentation.node.ts](/instrumentation.node.ts) to ensure proper configuration.

### Slow data refresh

- Metrics are exported every 15 seconds (configured in [instrumentation.node.ts:95](/instrumentation.node.ts#L95))
- The test scripts wait 20 seconds to ensure at least one export cycle completes
- Grafana dashboard refreshes every 15 seconds
- Prometheus scrapes the OTEL Collector every 10 seconds
- **Total latency**: Expect up to 20-30 seconds from script start to data appearing in Grafana

### Script exits but no data appears

If you ran a test script but don't see data in Grafana:

1. Make sure the script completed fully (waited the full 20 seconds)
2. Check if metrics exist in Prometheus:
   ```bash
   curl -s http://localhost:9090/api/v1/label/__name__/values | grep devacademy
   ```
3. If metrics exist but dashboards show "No data", adjust the time range in Grafana to "Last 15 minutes" or "Last 1 hour"
4. The test scripts generate metrics with the current timestamp - if your system clock is wrong, they won't appear in the expected time range

## Running in Production

These scripts are for **testing only**. Do not run them against production systems as they generate artificial load.

For production monitoring, your real application traffic will generate these metrics automatically through OpenTelemetry instrumentation.
